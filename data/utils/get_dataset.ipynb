{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e91dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ec90894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_colnames(n=100000):\n",
    "    all_colnames = [\n",
    "        '_id', 'title', 'authors', 'venue', 'year', 'keywords', \n",
    "        'fos', 'references', 'n_citation', 'page_start', 'page_end', \n",
    "        'lang', 'volume', 'issue', 'issn', 'isbn', 'doi', 'pdf', 'url',\n",
    "        'abstract',\n",
    "    ]\n",
    "#     all_colnames = set()\n",
    "#     with open('dblpv13_wo_numberint___.json', \"rb\") as f:\n",
    "#         for i, element in enumerate(tqdm(ijson.items(f, \"item\"))):\n",
    "#             all_colnames |= set(element.keys())\n",
    "#             if i == n:\n",
    "#                 break\n",
    "    return all_colnames\n",
    "\n",
    "def get_datalist(n=400_000, colnames=None):\n",
    "    colnames = colnames if colnames else get_all_colnames()\n",
    "    datalist = list()\n",
    "    with open('dblpv13_wo_numberint___.json', \"rb\") as f:\n",
    "        for i, element in enumerate(tqdm(ijson.items(f, \"item\")), total=n):\n",
    "            paper = {colname: element.get(colname, np.nan) for colname in colnames}\n",
    "            datalist.append(paper)\n",
    "            if i == n:\n",
    "                break\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ee27e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_json_wo_numberint(old_json_path='dblp.v13/dblpv13.json', n=10000):\n",
    "    with open(old_json_path) as old_json:\n",
    "        with open(\"dblpv13_wo_numberint.json\", \"w\") as new_json:\n",
    "            for line_num, old_line in enumerate(tqdm(old_json)):\n",
    "                new_line = old_line\n",
    "                new_line = re.sub(r'NumberInt\\((\\d+)\\)', r\"\\1\", new_line)\n",
    "                new_line = re.sub(r'NumberInt\\(\\)', \"null\", new_line)\n",
    "                new_json.write(new_line)\n",
    "#                 if line_num == n:\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "133dc64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409129302it [16:54, 403373.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# create_new_json_wo_numberint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bd6a01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'None'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json.loads('{\"type\" : \"None\"}')\n",
    "# re.sub(r'NumberInt\\((\\d+)\\)', r\"\\1\", '\"type\" : numberint(44442412)\\r\\n')\n",
    "# json.loads(re.sub(r'NumberInt\\(\\)', \"null\", '{\"type\" : NumberInt()\\r\\n}'))\n",
    "# json.loads('\"type\" : null\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ba19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331cd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../preprocessed_top_500k_papers_by_n_citation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db28c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:50000].to_csv(\"../preprocessed_top_50k_papers_by_n_citation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cdcc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63628171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '56d82a75dabfae2eeef900be',\n",
       " 'title': 'Multivariate Data Analysis',\n",
       " 'authors': [{'name': 'xianggui qu'}],\n",
       " 'venue': {'_id': '54824c96582fc50b5e00b6a4',\n",
       "  'raw': 'Technometrics',\n",
       "  'raw_zh': None,\n",
       "  'publisher': None,\n",
       "  'type': 11},\n",
       " 'year': 2012.0,\n",
       " 'keywords': '[]',\n",
       " 'fos': \"['Multivariate analysis of variance', 'Multivariate statistics', 'Statistics', 'Multivariate analysis', 'Business']\",\n",
       " 'references': nan,\n",
       " 'n_citation': 109033.0,\n",
       " 'page_start': nan,\n",
       " 'page_end': nan,\n",
       " 'lang': 'en',\n",
       " 'volume': '49',\n",
       " 'issue': '1',\n",
       " 'issn': nan,\n",
       " 'isbn': nan,\n",
       " 'doi': nan,\n",
       " 'pdf': 'https://static.aminer.cn/upload/pdf/1047/6/1169/56d82a75dabfae2eeef900be_0.pdf',\n",
       " 'url': \"['http://dx.doi.org/10.1198/tech.2007.s455']\",\n",
       " 'abstract': nan}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86f52989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 196.02it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter, paper in tqdm(enumerate(df.iterrows())):\n",
    "    if counter == 100:\n",
    "        break\n",
    "    paper = dict(paper[1])\n",
    "    for k, v in paper.items():\n",
    "        try:\n",
    "            paper[k] = ast.literal_eval(v)\n",
    "        except (SyntaxError, ValueError):\n",
    "            continue\n",
    "    #paper = {k: ast.literal_eval(v) for k, v in paper.items()}\n",
    "    #remove_incomplete_attributes(paper)\n",
    "    #crud.create_paper(schemas.Paper(**paper), session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49e75fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " _id                                    556f622a2401b4b38c23635c\n",
       " title         Rich Feature Hierarchies for Accurate Object D...\n",
       " authors       [{'_id': '53f4340adabfaec22ba6a6f8', 'name': '...\n",
       " venue         {'type': 0, 'raw': \"CVPR '14 Proceedings of th...\n",
       " year                                                     2014.0\n",
       " keywords      ['image segmentation', 'neural nets', 'object ...\n",
       " fos           ['Object detection', 'Pattern recognition', 'S...\n",
       " references    ['53e99818b7602d97020345eb', '53e9b45eb7602d97...\n",
       " n_citation                                              17226.0\n",
       " page_start                                                  580\n",
       " page_end                                                    587\n",
       " lang                                                         en\n",
       " volume                                                      NaN\n",
       " issue                                                       NaN\n",
       " issn                                                        NaN\n",
       " isbn                                                        NaN\n",
       " doi                                        10.1109/CVPR.2014.81\n",
       " pdf           https://static.aminer.cn/upload/pdf/program/55...\n",
       " url           ['http://ieeexplore.ieee.org/xpl/articleDetail...\n",
       " abstract      Object detection performance, as measured on t...\n",
       " Name: 100, dtype: object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "404cab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"a\": 1, \"b\": 3}, {\"c\": 4, \"a\": 4}]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps([{\"a\": 1, \"b\":3}, {\"c\":4, \"a\": 4}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74883fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "\n",
      "{ \n",
      "\n",
      "    \"_id\" : \"53e99784b7602d9701f3e3f5\", \n",
      "\n",
      "    \"title\" : \"3GIO.\", \n",
      "\n",
      "    \"venue\" : {\n",
      "\n",
      "        \"type\" : NumberInt(0)\n",
      "\n",
      "    }, \n",
      "\n",
      "    \"year\" : NumberInt(2011), \n",
      "\n",
      "    \"keywords\" : [\n",
      "\n",
      "\n",
      "\n",
      "    ], \n",
      "\n",
      "    \"n_citation\" : NumberInt(0), \n",
      "\n",
      "    \"lang\" : \"en\"\n",
      "\n",
      "},\n",
      "\n",
      "{ \n",
      "\n",
      "    \"_id\" : \"53e99784b7602d9701f3e133\", \n",
      "\n",
      "    \"title\" : \"The relationship between canopy parameters and spectrum of winter wheat under different irrigations in Hebei Province.\", \n",
      "\n",
      "    \"authors\" : [\n",
      "\n",
      "        {\n",
      "\n",
      "            \"_id\" : \"53f45728dabfaec09f209538\", \n",
      "\n",
      "            \"name\" : \"Peijuan Wang\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"../dblp.v13/dblpv13.json\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line)\n",
    "        if i == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66513fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'index=False' is only valid when 'orient' is 'split' or 'table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/generic.py:2650\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[1;32m   2647\u001b[0m config\u001b[38;5;241m.\u001b[39mis_nonnegative_int(indent)\n\u001b[1;32m   2648\u001b[0m indent \u001b[38;5;241m=\u001b[39m indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/json/_json.py:141\u001b[0m, in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_json\u001b[39m(\n\u001b[1;32m    125\u001b[0m     path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m     obj: NDFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m index \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex=False\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only valid when \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morient\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         )\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lines \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword only valid when \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morient\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'index=False' is only valid when 'orient' is 'split' or 'table'"
     ]
    }
   ],
   "source": [
    "df.iloc[:5].to_json(orient=\"index\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067889fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56d82a75dabfae2eeef900be', 'title': 'Multivariate Data Analysis', 'authors': \"[{'name': 'xianggui qu'}]\", 'venue': \"{'id': '54824c96582fc50b5e00b6a4', 'raw': 'Technometrics', 'raw_zh': None, 'publisher': None, 'type': 11}\", 'year': 2012.0, 'keywords': '[]', 'fos': \"['Multivariate analysis of variance', 'Multivariate statistics', 'Statistics', 'Multivariate analysis', 'Business']\", 'references': nan, 'n_citation': 109033.0, 'page_start': nan, 'page_end': nan, 'lang': 'en', 'volume': '49', 'issue': '1', 'issn': nan, 'isbn': nan, 'doi': nan, 'pdf': 'https://static.aminer.cn/upload/pdf/1047/6/1169/56d82a75dabfae2eeef900be_0.pdf', 'url': \"['http://dx.doi.org/10.1198/tech.2007.s455']\", 'abstract': nan}\n",
      "{'id': '599c7f08601a182cd28e5abd', 'title': 'ImageNet Classification with Deep Convolutional Neural Networks.', 'authors': \"[{'name': 'Alex Krizhevsky', 'sid': 'Alex Krizhevsky'}, {'name': 'Ilya Sutskever', 'sid': 'Ilya Sutskever', 'id': '53f458fcdabfaeecd69f5094'}, {'name': 'Geoffrey E. Hinton', 'sid': 'Geoffrey E. Hinton', 'id': '53f366a7dabfae4b3499c6fe'}]\", 'venue': \"{'id': '5d3571d9f1cb7f61c53630fc', 'sid': 'conf/nips', 'name': 'Neural Information Processing Systems (NeurIPS)', 't': 'C', 'raw': 'NIPS'}\", 'year': 2012.0, 'keywords': nan, 'fos': \"['Rectifier (neural networks)', 'MNIST database', 'Softmax function', 'Pattern recognition', 'Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Deep learning', 'Artificial neural network', 'TrueNorth', 'Vanishing gradient problem', 'Machine learning']\", 'references': \"['53e9bbf0b7602d970484568d', '53e9ba4ab7602d97046616bc', '53e9bc32b7602d97048a21c8', '53e99da4b7602d970265f665', '53e9be0fb7602d9704ac6ec3', '53e9ad0ab7602d97036e7894', '56d83bdcdabfae2eee6416bd', '53e9be2eb7602d9704aec6ec', '53e9b844b7602d970440513c', '53e9ab97b7602d9703541745', '53e9b9e7b7602d97045e36b5', '53e9b428b7602d9703f20faa', '53e99e71b7602d9702734c59', '53e9a7acb7602d97030ebcb1', '53e9a749b7602d9703080fee', '558c5f3284ae6766fdf2b1e2', '53e99e45b7602d970270cc54', '53e998c7b7602d97020ff17e', '53e9b8e9b7602d97044ceee2', '53e9a508b7602d9702e2bcf5']\", 'n_citation': 83170.0, 'page_start': '1106', 'page_end': '1114', 'lang': nan, 'volume': nan, 'issue': nan, 'issn': nan, 'isbn': nan, 'doi': nan, 'pdf': 'https://static.aminer.cn/upload/pdf/842/639/1465/599c7f08601a182cd28e5abd_0.pdf', 'url': \"['db/conf/nips/nips2012.html#KrizhevskySH12', 'http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks']\", 'abstract': nan}\n",
      "{'id': '558c0517e4b00c3c48dfc989', 'title': 'A mathematical theory of communication', 'authors': \"[{'id': '563397ad45cedb339aaa7a43', 'name': 'Claude E. Shannon', 'sid': 'Claude E. Shannon'}]\", 'venue': \"{'id': '53907c1720f770854f5ff32a', 'raw': 'ACM SIGMOBILE Mobile Computing and Communications Review'}\", 'year': 1948.0, 'keywords': \"['mathematical theory']\", 'fos': \"['Applied mathematics', 'Sociology of scientific knowledge', 'Computer science', 'Communication theory', 'Mathematical theory', 'Futures studies', 'Information algebra']\", 'references': nan, 'n_citation': 77820.0, 'page_start': '379', 'page_end': '423', 'lang': 'en', 'volume': '27', 'issue': '3', 'issn': '0005-8580', 'isbn': nan, 'doi': '10.1002/j.1538-7305.1948.tb01338.x', 'pdf': nan, 'url': \"['http://ieeexplore.ieee.org/xpl/abstractAuthors.jsp?tp=&arnumber=6773024', 'db/journals/bstj/bstj27.html#Shannon48', 'https://doi.org/10.1002/j.1538-7305.1948.tb01338.x', 'http://dx.doi.org/10.1145/584091.584093', 'http://doi.acm.org/10.1145/584091.584093', 'db/journals/bstj/bstj27.html#Shannon48a', 'https://doi.org/10.1002/j.1538-7305.1948.tb00917.x']\", 'abstract': 'The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.'}\n",
      "{'id': '53e9a690b7602d9702fc0e24', 'title': 'The nature of statistical learning theory', 'authors': \"[{'id': '53f4ba36dabfaed83977b7aa', 'name': 'Vladimir N. Vapnik', 'org': 'AT&T Bell Labs, Holmdel, NJ', 'gid': '5b86b6d5e1cd8e14a34d3333', 'orgid': '5f71b2811c455f439fe3c58e'}]\", 'venue': \"{'id': '53907ab920f770854f5dcaf7', 'name': 'IEEE Transactions on Neural Networks', 'type': 0, 'raw': 'The nature of statistical learning theory'}\", 'year': 1995.0, 'keywords': \"['statistical learning theory', 'risk management', 'machine learning', 'parametric statistics', 'training data', 'statistical analysis', 'neural networks', 'support vector machines']\", 'fos': \"['Statistical learning theory', 'Algorithmic learning theory', 'Instance-based learning', 'Stability (learning theory)', 'Cognitive science', 'Computer science', 'Empirical risk minimization', 'Unsupervised learning', 'Artificial intelligence', 'Computational learning theory', 'Ensemble learning', 'Machine learning']\", 'references': nan, 'n_citation': 76991.0, 'page_start': nan, 'page_end': nan, 'lang': 'en', 'volume': nan, 'issue': nan, 'issn': nan, 'isbn': '0-387-94559-8', 'doi': '10.1109/TNN.1997.641482', 'pdf': nan, 'url': \"['http://dx.doi.org/10.1109/TNN.1997.641482']\", 'abstract': nan}\n",
      "{'id': '573696026e3b12023e515eec', 'title': 'Deep Residual Learning for Image Recognition', 'authors': \"[{'id': '53f431badabfaee02ac9803b', 'name': 'kaiming he'}, {'id': '562c7eaa45cedb3398c3cfba', 'name': 'xiangyu zhang'}, {'id': '53f42b4fdabfaedce54a3fe9', 'name': 'shaoqing ren'}, {'id': '53f43097dabfaedf4353f3bc', 'name': 'jian sun'}]\", 'venue': \"{'id': '53a7256420f7420be8b4e0aa', 'type': 10, 'raw': 'CVPR'}\", 'year': 2016.0, 'keywords': '[]', 'fos': \"['MNIST database', 'Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Artificial neural network', 'Residual', 'Object detection', 'Computer vision', 'Pattern recognition', 'Vanishing gradient problem', 'Feature learning', 'Machine learning']\", 'references': \"['5550415945ce0a409eb3a820', '5550415c45ce0a409eb3a9a8', '53e9ae4eb7602d9703866d7d', '573697846e3b12023e66aa2d', '573696f46e3b12023e5f15b5', '53e9a80cb7602d970314bf39', '53e99c7cb7602d970252a49c', '5550415645ce0a409eb3a69e', '556f622a2401b4b38c23635c', '53e9ba85b7602d97046aa61d', '5736986b6e3b12023e730129', '53e9ae36b7602d970384bdf4', '53e9a479b7602d9702d98afa', '557ee0d2d19faf961d16d246', '557d03c7f667eeed56196422', '56d81594dabfae2eee6f5b7f', '53e9a508b7602d9702e2bcf5', '573696f46e3b12023e5f0d4d', '53e9b75ab7602d97042fadd4', '53e9b682b7602d97041ee1b2', '53e99a85b7602d97022f8644', '55465d900cf2939c2fee792b', '53e99fbcb7602d970289688c', '573696f46e3b12023e5f1198', '53e9ac69b7602d9703637d08', '5550418245ce0a409eb3bebb', '53e9b428b7602d9703f20faa', '599c7f08601a182cd28e5abd', '53e99fc2b7602d9702899ee6', '573697826e3b12023e6694d1', '53e9a186b7602d9702a772f5', '573696ce6e3b12023e5ce95a', '53e9b102b7602d9703b7e501', '53e9a675b7602d9702fa41e9', '5550417d45ce0a409eb3bc08', '53e99da4b7602d970265df42']\", 'n_citation': 73009.0, 'page_start': nan, 'page_end': nan, 'lang': 'en', 'volume': 'abs/1512.03385', 'issue': nan, 'issn': nan, 'isbn': nan, 'doi': nan, 'pdf': 'https://static.aminer.cn/upload/pdf/program/573696026e3b12023e515eec_0.pdf', 'url': \"['http://arxiv.org/abs/1512.03385', 'http://dx.doi.org/10.1109/CVPR.2016.90', 'http://doi.ieeecomputersociety.org/10.1109/CVPR.2016.90', 'https://arxiv.org/abs/1512.03385']\", 'abstract': '  Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.   The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. '}\n",
      "{'id': '53e9a281b7602d9702b88a98', 'title': 'ImageNet Classification with Deep Convolutional Neural Networks.', 'authors': \"[{'id': '53f433bfdabfaec22ba66fb5', 'name': 'Alex Krizhevsky', 'org': 'Google Inc', 'orgs': [], 'gid': '5b86b6d0e1cd8e14a34d1490', 'orgid': '5f71b2d21c455f439fe3e823'}, {'id': '53f458fcdabfaeecd69f5094', 'name': 'Ilya Sutskever', 'org': 'Google Inc', 'orgs': [], 'gid': '5b86b6d0e1cd8e14a34d1490', 'orgid': '5f71b2d21c455f439fe3e823'}, {'id': '53f366a7dabfae4b3499c6fe', 'name': 'Geoffrey E. Hinton', 'org': 'OpenAI', 'orgs': [], 'gid': '5b869b52e1cd8e14a39413a3', 'orgid': '5f71b64f1c455f439fe57028'}]\", 'venue': \"{'type': 11, 'raw': 'Commun. ACM'}\", 'year': 2017.0, 'keywords': '[]', 'fos': \"['Rectifier (neural networks)', 'MNIST database', 'Convolutional neural network', 'Computer science', 'Regularization (mathematics)', 'Test error rate', 'Artificial intelligence', 'Overfitting', 'Deep learning', 'Artificial neural network', 'Softmax function', 'Pattern recognition', 'Convolution', 'Test data', 'TrueNorth', 'Vanishing gradient problem', 'Machine learning']\", 'references': \"['53e9bbf0b7602d970484568d', '53e9ba4ab7602d97046616bc', '53e9bc32b7602d97048a21c8', '53e99da4b7602d970265f665', '53e9be0fb7602d9704ac6ec3', '53e9ace2b7602d97036c1881', '53e9ad0ab7602d97036e7894', '56d83bdcdabfae2eee6416bd', '53e9be2eb7602d9704aec6ec', '53e9b844b7602d970440513c', '53e9ab97b7602d9703541745', '53e9b9e7b7602d97045e36b5', '53e9b428b7602d9703f20faa', '53e99e71b7602d9702734c59', '573696026e3b12023e515eec', '53e9a7acb7602d97030ebcb1', '53e9a749b7602d9703080fee', '558c5f3284ae6766fdf2b1e2', '53e99e45b7602d970270cc54', '53e998c7b7602d97020ff17e', '53e9b8e9b7602d97044ceee2', '5550417d45ce0a409eb3bc08', '53e9a508b7602d9702e2bcf5']\", 'n_citation': 72606.0, 'page_start': '84', 'page_end': '90', 'lang': 'en', 'volume': '60', 'issue': '6', 'issn': nan, 'isbn': nan, 'doi': nan, 'pdf': '//static.aminer.org/pdf/20160902/web-conf/NIPS/NIPS-2012-2381.pdf', 'url': \"['http://doi.acm.org/10.1145/3065386', 'https://dl.acm.org/doi/10.1145/3065386']\", 'abstract': 'We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \\\\\"dropout\\\\\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.'}\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(df.iterrows()):\n",
    "    print(dict(row[1]))\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2864f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"schema\":{\"fields\":[{\"name\":\"_id\",\"type\":\"string\"},{\"name\":\"title\",\"type\":\"string\"},{\"name\":\"authors\",\"type\":\"string\"},{\"name\":\"venue\",\"type\":\"string\"},{\"name\":\"year\",\"type\":\"number\"},{\"name\":\"keywords\",\"type\":\"string\"},{\"name\":\"fos\",\"type\":\"string\"},{\"name\":\"references\",\"type\":\"string\"},{\"name\":\"n_citation\",\"type\":\"number\"},{\"name\":\"page_start\",\"type\":\"string\"},{\"name\":\"page_end\",\"type\":\"string\"},{\"name\":\"lang\",\"type\":\"string\"},{\"name\":\"volume\",\"type\":\"string\"},{\"name\":\"issue\",\"type\":\"string\"},{\"name\":\"issn\",\"type\":\"string\"},{\"name\":\"isbn\",\"type\":\"string\"},{\"name\":\"doi\",\"type\":\"string\"},{\"name\":\"pdf\",\"type\":\"string\"},{\"name\":\"url\",\"type\":\"string\"},{\"name\":\"abstract\",\"type\":\"string\"}],\"pandas_version\":\"1.4.0\"},\"data\":[{\"_id\":\"56d82a75dabfae2eeef900be\",\"title\":\"Multivariate Data Analysis\",\"authors\":\"[{\\'name\\': \\'xianggui qu\\'}]\",\"venue\":\"{\\'_id\\': \\'54824c96582fc50b5e00b6a4\\', \\'raw\\': \\'Technometrics\\', \\'raw_zh\\': None, \\'publisher\\': None, \\'type\\': 11}\",\"year\":2012.0,\"keywords\":\"[]\",\"fos\":\"[\\'Multivariate analysis of variance\\', \\'Multivariate statistics\\', \\'Statistics\\', \\'Multivariate analysis\\', \\'Business\\']\",\"references\":null,\"n_citation\":109033.0,\"page_start\":null,\"page_end\":null,\"lang\":\"en\",\"volume\":\"49\",\"issue\":\"1\",\"issn\":null,\"isbn\":null,\"doi\":null,\"pdf\":\"https:\\\\/\\\\/static.aminer.cn\\\\/upload\\\\/pdf\\\\/1047\\\\/6\\\\/1169\\\\/56d82a75dabfae2eeef900be_0.pdf\",\"url\":\"[\\'http:\\\\/\\\\/dx.doi.org\\\\/10.1198\\\\/tech.2007.s455\\']\",\"abstract\":null},{\"_id\":\"599c7f08601a182cd28e5abd\",\"title\":\"ImageNet Classification with Deep Convolutional Neural Networks.\",\"authors\":\"[{\\'name\\': \\'Alex Krizhevsky\\', \\'sid\\': \\'Alex Krizhevsky\\'}, {\\'name\\': \\'Ilya Sutskever\\', \\'sid\\': \\'Ilya Sutskever\\', \\'_id\\': \\'53f458fcdabfaeecd69f5094\\'}, {\\'name\\': \\'Geoffrey E. Hinton\\', \\'sid\\': \\'Geoffrey E. Hinton\\', \\'_id\\': \\'53f366a7dabfae4b3499c6fe\\'}]\",\"venue\":\"{\\'_id\\': \\'5d3571d9f1cb7f61c53630fc\\', \\'sid\\': \\'conf\\\\/nips\\', \\'name\\': \\'Neural Information Processing Systems (NeurIPS)\\', \\'t\\': \\'C\\', \\'raw\\': \\'NIPS\\'}\",\"year\":2012.0,\"keywords\":null,\"fos\":\"[\\'Rectifier (neural networks)\\', \\'MNIST database\\', \\'Softmax function\\', \\'Pattern recognition\\', \\'Computer science\\', \\'Convolutional neural network\\', \\'Artificial intelligence\\', \\'Deep learning\\', \\'Artificial neural network\\', \\'TrueNorth\\', \\'Vanishing gradient problem\\', \\'Machine learning\\']\",\"references\":\"[\\'53e9bbf0b7602d970484568d\\', \\'53e9ba4ab7602d97046616bc\\', \\'53e9bc32b7602d97048a21c8\\', \\'53e99da4b7602d970265f665\\', \\'53e9be0fb7602d9704ac6ec3\\', \\'53e9ad0ab7602d97036e7894\\', \\'56d83bdcdabfae2eee6416bd\\', \\'53e9be2eb7602d9704aec6ec\\', \\'53e9b844b7602d970440513c\\', \\'53e9ab97b7602d9703541745\\', \\'53e9b9e7b7602d97045e36b5\\', \\'53e9b428b7602d9703f20faa\\', \\'53e99e71b7602d9702734c59\\', \\'53e9a7acb7602d97030ebcb1\\', \\'53e9a749b7602d9703080fee\\', \\'558c5f3284ae6766fdf2b1e2\\', \\'53e99e45b7602d970270cc54\\', \\'53e998c7b7602d97020ff17e\\', \\'53e9b8e9b7602d97044ceee2\\', \\'53e9a508b7602d9702e2bcf5\\']\",\"n_citation\":83170.0,\"page_start\":\"1106\",\"page_end\":\"1114\",\"lang\":null,\"volume\":null,\"issue\":null,\"issn\":null,\"isbn\":null,\"doi\":null,\"pdf\":\"https:\\\\/\\\\/static.aminer.cn\\\\/upload\\\\/pdf\\\\/842\\\\/639\\\\/1465\\\\/599c7f08601a182cd28e5abd_0.pdf\",\"url\":\"[\\'db\\\\/conf\\\\/nips\\\\/nips2012.html#KrizhevskySH12\\', \\'http:\\\\/\\\\/papers.nips.cc\\\\/paper\\\\/4824-imagenet-classification-with-deep-convolutional-neural-networks\\']\",\"abstract\":null},{\"_id\":\"558c0517e4b00c3c48dfc989\",\"title\":\"A mathematical theory of communication\",\"authors\":\"[{\\'_id\\': \\'563397ad45cedb339aaa7a43\\', \\'name\\': \\'Claude E. Shannon\\', \\'sid\\': \\'Claude E. Shannon\\'}]\",\"venue\":\"{\\'_id\\': \\'53907c1720f770854f5ff32a\\', \\'raw\\': \\'ACM SIGMOBILE Mobile Computing and Communications Review\\'}\",\"year\":1948.0,\"keywords\":\"[\\'mathematical theory\\']\",\"fos\":\"[\\'Applied mathematics\\', \\'Sociology of scientific knowledge\\', \\'Computer science\\', \\'Communication theory\\', \\'Mathematical theory\\', \\'Futures studies\\', \\'Information algebra\\']\",\"references\":null,\"n_citation\":77820.0,\"page_start\":\"379\",\"page_end\":\"423\",\"lang\":\"en\",\"volume\":\"27\",\"issue\":\"3\",\"issn\":\"0005-8580\",\"isbn\":null,\"doi\":\"10.1002\\\\/j.1538-7305.1948.tb01338.x\",\"pdf\":null,\"url\":\"[\\'http:\\\\/\\\\/ieeexplore.ieee.org\\\\/xpl\\\\/abstractAuthors.jsp?tp=&arnumber=6773024\\', \\'db\\\\/journals\\\\/bstj\\\\/bstj27.html#Shannon48\\', \\'https:\\\\/\\\\/doi.org\\\\/10.1002\\\\/j.1538-7305.1948.tb01338.x\\', \\'http:\\\\/\\\\/dx.doi.org\\\\/10.1145\\\\/584091.584093\\', \\'http:\\\\/\\\\/doi.acm.org\\\\/10.1145\\\\/584091.584093\\', \\'db\\\\/journals\\\\/bstj\\\\/bstj27.html#Shannon48a\\', \\'https:\\\\/\\\\/doi.org\\\\/10.1002\\\\/j.1538-7305.1948.tb00917.x\\']\",\"abstract\":\"The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.\"},{\"_id\":\"53e9a690b7602d9702fc0e24\",\"title\":\"The nature of statistical learning theory\",\"authors\":\"[{\\'_id\\': \\'53f4ba36dabfaed83977b7aa\\', \\'name\\': \\'Vladimir N. Vapnik\\', \\'org\\': \\'AT&T Bell Labs, Holmdel, NJ\\', \\'gid\\': \\'5b86b6d5e1cd8e14a34d3333\\', \\'orgid\\': \\'5f71b2811c455f439fe3c58e\\'}]\",\"venue\":\"{\\'_id\\': \\'53907ab920f770854f5dcaf7\\', \\'name_d\\': \\'IEEE Transactions on Neural Networks\\', \\'type\\': 0, \\'raw\\': \\'The nature of statistical learning theory\\'}\",\"year\":1995.0,\"keywords\":\"[\\'statistical learning theory\\', \\'risk management\\', \\'machine learning\\', \\'parametric statistics\\', \\'training data\\', \\'statistical analysis\\', \\'neural networks\\', \\'support vector machines\\']\",\"fos\":\"[\\'Statistical learning theory\\', \\'Algorithmic learning theory\\', \\'Instance-based learning\\', \\'Stability (learning theory)\\', \\'Cognitive science\\', \\'Computer science\\', \\'Empirical risk minimization\\', \\'Unsupervised learning\\', \\'Artificial intelligence\\', \\'Computational learning theory\\', \\'Ensemble learning\\', \\'Machine learning\\']\",\"references\":null,\"n_citation\":76991.0,\"page_start\":null,\"page_end\":null,\"lang\":\"en\",\"volume\":null,\"issue\":null,\"issn\":null,\"isbn\":\"0-387-94559-8\",\"doi\":\"10.1109\\\\/TNN.1997.641482\",\"pdf\":null,\"url\":\"[\\'http:\\\\/\\\\/dx.doi.org\\\\/10.1109\\\\/TNN.1997.641482\\']\",\"abstract\":null},{\"_id\":\"573696026e3b12023e515eec\",\"title\":\"Deep Residual Learning for Image Recognition\",\"authors\":\"[{\\'_id\\': \\'53f431badabfaee02ac9803b\\', \\'name\\': \\'kaiming he\\'}, {\\'_id\\': \\'562c7eaa45cedb3398c3cfba\\', \\'name\\': \\'xiangyu zhang\\'}, {\\'_id\\': \\'53f42b4fdabfaedce54a3fe9\\', \\'name\\': \\'shaoqing ren\\'}, {\\'_id\\': \\'53f43097dabfaedf4353f3bc\\', \\'name\\': \\'jian sun\\'}]\",\"venue\":\"{\\'_id\\': \\'53a7256420f7420be8b4e0aa\\', \\'type\\': 10, \\'raw\\': \\'CVPR\\'}\",\"year\":2016.0,\"keywords\":\"[]\",\"fos\":\"[\\'MNIST database\\', \\'Convolutional neural network\\', \\'Computer science\\', \\'Artificial intelligence\\', \\'Deep learning\\', \\'Artificial neural network\\', \\'Residual\\', \\'Object detection\\', \\'Computer vision\\', \\'Pattern recognition\\', \\'Vanishing gradient problem\\', \\'Feature learning\\', \\'Machine learning\\']\",\"references\":\"[\\'5550415945ce0a409eb3a820\\', \\'5550415c45ce0a409eb3a9a8\\', \\'53e9ae4eb7602d9703866d7d\\', \\'573697846e3b12023e66aa2d\\', \\'573696f46e3b12023e5f15b5\\', \\'53e9a80cb7602d970314bf39\\', \\'53e99c7cb7602d970252a49c\\', \\'5550415645ce0a409eb3a69e\\', \\'556f622a2401b4b38c23635c\\', \\'53e9ba85b7602d97046aa61d\\', \\'5736986b6e3b12023e730129\\', \\'53e9ae36b7602d970384bdf4\\', \\'53e9a479b7602d9702d98afa\\', \\'557ee0d2d19faf961d16d246\\', \\'557d03c7f667eeed56196422\\', \\'56d81594dabfae2eee6f5b7f\\', \\'53e9a508b7602d9702e2bcf5\\', \\'573696f46e3b12023e5f0d4d\\', \\'53e9b75ab7602d97042fadd4\\', \\'53e9b682b7602d97041ee1b2\\', \\'53e99a85b7602d97022f8644\\', \\'55465d900cf2939c2fee792b\\', \\'53e99fbcb7602d970289688c\\', \\'573696f46e3b12023e5f1198\\', \\'53e9ac69b7602d9703637d08\\', \\'5550418245ce0a409eb3bebb\\', \\'53e9b428b7602d9703f20faa\\', \\'599c7f08601a182cd28e5abd\\', \\'53e99fc2b7602d9702899ee6\\', \\'573697826e3b12023e6694d1\\', \\'53e9a186b7602d9702a772f5\\', \\'573696ce6e3b12023e5ce95a\\', \\'53e9b102b7602d9703b7e501\\', \\'53e9a675b7602d9702fa41e9\\', \\'5550417d45ce0a409eb3bc08\\', \\'53e99da4b7602d970265df42\\']\",\"n_citation\":73009.0,\"page_start\":null,\"page_end\":null,\"lang\":\"en\",\"volume\":\"abs\\\\/1512.03385\",\"issue\":null,\"issn\":null,\"isbn\":null,\"doi\":null,\"pdf\":\"https:\\\\/\\\\/static.aminer.cn\\\\/upload\\\\/pdf\\\\/program\\\\/573696026e3b12023e515eec_0.pdf\",\"url\":\"[\\'http:\\\\/\\\\/arxiv.org\\\\/abs\\\\/1512.03385\\', \\'http:\\\\/\\\\/dx.doi.org\\\\/10.1109\\\\/CVPR.2016.90\\', \\'http:\\\\/\\\\/doi.ieeecomputersociety.org\\\\/10.1109\\\\/CVPR.2016.90\\', \\'https:\\\\/\\\\/arxiv.org\\\\/abs\\\\/1512.03385\\']\",\"abstract\":\"  Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.   The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. \"}]}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5].to_json(orient=\"table\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbab337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00cc9168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '56d82a75dabfae2eeef900be', 'title': 'Multivariate Data Analysis', 'authors': \"[{'name': 'xianggui qu'}]\", 'venue': \"{'_id': '54824c96582fc50b5e00b6a4', 'raw': 'Technometrics', 'raw_zh': None, 'publisher': None, 'type': 11}\", 'year': 2012.0, 'keywords': '[]', 'fos': \"['Multivariate analysis of variance', 'Multivariate statistics', 'Statistics', 'Multivariate analysis', 'Business']\", 'references': nan, 'n_citation': 109033.0, 'page_start': nan, 'page_end': nan, 'lang': 'en', 'volume': '49', 'issue': '1', 'issn': nan, 'isbn': nan, 'doi': nan, 'pdf': 'https://static.aminer.cn/upload/pdf/1047/6/1169/56d82a75dabfae2eeef900be_0.pdf', 'url': \"['http://dx.doi.org/10.1198/tech.2007.s455']\", 'abstract': nan}\n"
     ]
    }
   ],
   "source": [
    "for row in dfs.iterrows():\n",
    "    print(dict(row[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08664483",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15a7d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:01, 57389.80it/s]\n"
     ]
    }
   ],
   "source": [
    "all_colnames = get_all_colnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dfc7d46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id',\n",
       " 'abstract',\n",
       " 'authors',\n",
       " 'doi',\n",
       " 'fos',\n",
       " 'isbn',\n",
       " 'issn',\n",
       " 'issue',\n",
       " 'keywords',\n",
       " 'lang',\n",
       " 'n_citation',\n",
       " 'page_end',\n",
       " 'page_start',\n",
       " 'pdf',\n",
       " 'references',\n",
       " 'title',\n",
       " 'url',\n",
       " 'venue',\n",
       " 'volume',\n",
       " 'year'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb879eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "976bdaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29548522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "# import argparse\n",
    "# import asyncio\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4a03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(input_file, output_file):\n",
    "    for i, line in tqdm.tqdm(enumerate(input_file)):\n",
    "        line = re.sub(r\"_id\", 'id', line)\n",
    "        line = re.sub(r\"name_d\", \"name\", line)\n",
    "        line = re.sub(r\"NumberInt\\(([0-9]+)\\)\", r\"\\1\", line)\n",
    "        output_file.write(line)\n",
    "#         if i == 1000:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd1426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1247534it [00:05, 215902.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dblp.v13/dblpv13.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dblpv13.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 5\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m line \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, line)\n\u001b[1;32m      4\u001b[0m line \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mname_d\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, line)\n\u001b[0;32m----> 5\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNumberInt\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m(([0-9]+)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m output_file\u001b[38;5;241m.\u001b[39mwrite(line)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/re.py:210\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/re.py:327\u001b[0m, in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subx\u001b[39m(pattern, template):\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# internal: Pattern.sub/subn implementation helper\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[43m_compile_repl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m template[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(template[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;66;03m# literal replacement\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m template[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"../dblp.v13/dblpv13.json\", \"r\", encoding=\"UTF-8\") as input_file:\n",
    "    with open(\"../dblpv13.json\", \"w\", encoding=\"UTF-8\") as output_file:\n",
    "        prepare(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0e11e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "575437it [00:21, 26892.06it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../top_500k_papers_by_n_citation.csv\", \"r\", encoding=\"UTF-8\") as input_file:\n",
    "    with open(\"../preprocessed_top_500k_papers_by_n_citation.csv\", \"w\", encoding=\"UTF-8\") as output_file:\n",
    "        prepare(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2350341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
